{"version":3,"file":"/packages/spiderable.js","sources":["spiderable/spiderable.js","spiderable/spiderable_server.js"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA,gB;;;;;;;;;;;;;;;;;;;;ACAA,2B;AACA,iD;AACA,6C;AACA,mC;;AAEA,mE;AACA,+D;AACA,gE;AACA,wC;AACA,E;AACA,kE;AACA,qE;AACA,iE;AACA,8B;AACA,+B;AACA,8D;;AAEA,kD;AACA,8B;AACA,mE;AACA,sB;AACA,oC;;AAEA,sB;AACA,oE;AACA,wD;AACA,8C;AACA,uD;AACA,2C;;AAEA,2D;AACA,wE;AACA,wE;AACA,mE;AACA,c;AACA,6C;AACA,yD;AACA,G;AACA,4E;AACA,qE;AACA,wC;AACA,6D;AACA,kC;;AAEA,6C;AACA,E;;AAEA,yD;;AAEA,sD;AACA,+D;AACA,8E;AACA,0E;AACA,mE;AACA,+E;AACA,+E;AACA,wE;AACA,gD;AACA,wD;AACA,wD;;AAEA,uE;;AAEA,2E;AACA,8E;AACA,sE;AACA,6E;AACA,0E;AACA,Y;AACA,kE;AACA,yB;;AAEA,qB;AACA,M;AACA,sE;AACA,iE;AACA,+C;AACA,M;AACA,oE;AACA,2E;AACA,6E;AACA,wE;AACA,6E;AACA,kB;AACA,2B;AACA,kB;AACA,Y;AACA,gE;AACA,kC;AACA,wD;AACA,wC;AACA,8C;AACA,2E;AACA,0B;AACA,gB;AACA,qE;AACA,yB;AACA,0C;AACA,kH;AACA,c;AACA,uF;;AAEA,iB;AACA,S;AACA,S;AACA,U;AACA,W;AACA,G;AACA,G","sourcesContent":["Spiderable = {};\n\n","var fs = Npm.require('fs');\nvar child_process = Npm.require('child_process');\nvar querystring = Npm.require('querystring');\nvar urlParser = Npm.require('url');\n\n// list of bot user agents that we want to serve statically, but do\n// not obey the _escaped_fragment_ protocol. The page is served\n// statically to any client whos user agent matches any of these\n// regexps. Users may modify this array.\n//\n// An original goal with the spiderable package was to avoid doing\n// user-agent based tests. But the reality is not enough bots support\n// the _escaped_fragment_ protocol, so we need to hardcode a list\n// here. I shed a silent tear.\nSpiderable.userAgentRegExps = [\n    /^facebookexternalhit/i, /^linkedinbot/i, /^twitterbot/i];\n\n// how long to let phantomjs run before we kill it\nvar REQUEST_TIMEOUT = 15*1000;\n// maximum size of result HTML. node's default is 200k which is too\n// small for our docs.\nvar MAX_BUFFER = 5*1024*1024; // 5MB\n\n// Exported for tests.\nSpiderable._urlForPhantom = function (siteAbsoluteUrl, requestUrl) {\n  // reassembling url without escaped fragment if exists\n  var parsedUrl = urlParser.parse(requestUrl);\n  var parsedQuery = querystring.parse(parsedUrl.query);\n  delete parsedQuery['_escaped_fragment_'];\n\n  var parsedAbsoluteUrl = urlParser.parse(siteAbsoluteUrl);\n  // If the ROOT_URL contains a path, Meteor strips that path off of the\n  // request's URL before we see it. So we concatenate the pathname from\n  // the request's URL with the root URL's pathname to get the full\n  // pathname.\n  if (parsedUrl.pathname.charAt(0) === \"/\") {\n    parsedUrl.pathname = parsedUrl.pathname.substring(1);\n  }\n  parsedAbsoluteUrl.pathname = urlParser.resolve(parsedAbsoluteUrl.pathname,\n                                                 parsedUrl.pathname);\n  parsedAbsoluteUrl.query = parsedQuery;\n  // `url.format` will only use `query` if `search` is absent\n  parsedAbsoluteUrl.search = null;\n\n  return urlParser.format(parsedAbsoluteUrl);\n};\n\nvar PHANTOM_SCRIPT = Assets.getText(\"phantom_script.js\");\n\nWebApp.connectHandlers.use(function (req, res, next) {\n  // _escaped_fragment_ comes from Google's AJAX crawling spec:\n  // https://developers.google.com/webmasters/ajax-crawling/docs/specification\n  // This spec was designed during the brief era where using \"#!\" URLs was\n  // common, so it mostly describes how to translate \"#!\" URLs into\n  // _escaped_fragment_ URLs. Since then, \"#!\" URLs have gone out of style, but\n  // the <meta name=\"fragment\" content=\"!\"> (see spiderable.html) approach also\n  // described in the spec is still common and used by several crawlers.\n  if (/\\?.*_escaped_fragment_=/.test(req.url) ||\n      _.any(Spiderable.userAgentRegExps, function (re) {\n        return re.test(req.headers['user-agent']); })) {\n\n    var url = Spiderable._urlForPhantom(Meteor.absoluteUrl(), req.url);\n\n    // This string is going to be put into a bash script, so it's important\n    // that 'url' (which comes from the network) can neither exploit phantomjs\n    // or the bash script. JSON stringification should prevent it from\n    // exploiting phantomjs, and since the output of JSON.stringify shouldn't\n    // be able to contain newlines, it should be unable to exploit bash as\n    // well.\n    var phantomScript = \"var url = \" + JSON.stringify(url) + \";\" +\n          PHANTOM_SCRIPT;\n\n    // Run phantomjs.\n    //\n    // Use '/dev/stdin' to avoid writing to a temporary file. We can't\n    // just omit the file, as PhantomJS takes that to mean 'use a\n    // REPL' and exits as soon as stdin closes.\n    //\n    // However, Node 0.8 broke the ability to open /dev/stdin in the\n    // subprocess, so we can't just write our string to the process's stdin\n    // directly; see https://gist.github.com/3751746 for the gory details. We\n    // work around this with a bash heredoc. (We previous used a \"cat |\"\n    // instead, but that meant we couldn't use exec and had to manage several\n    // processes.)\n    child_process.execFile(\n      '/bin/bash',\n      ['-c',\n       (\"exec phantomjs --load-images=no /dev/stdin <<'END'\\n\" +\n        phantomScript + \"END\\n\")],\n      {timeout: REQUEST_TIMEOUT, maxBuffer: MAX_BUFFER},\n      function (error, stdout, stderr) {\n        if (!error && /<html/i.test(stdout)) {\n          res.writeHead(200, {'Content-Type': 'text/html; charset=UTF-8'});\n          res.end(stdout);\n        } else {\n          // phantomjs failed. Don't send the error, instead send the\n          // normal page.\n          if (error && error.code === 127)\n            Meteor._debug(\"spiderable: phantomjs not installed. Download and install from http://phantomjs.org/\");\n          else\n            Meteor._debug(\"spiderable: phantomjs failed:\", error, \"\\nstderr:\", stderr);\n\n          next();\n        }\n      });\n  } else {\n    next();\n  }\n});\n"]}